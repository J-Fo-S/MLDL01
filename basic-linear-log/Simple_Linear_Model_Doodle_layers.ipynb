{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial #01\n",
    "# Simple Linear Model with Google Doodle\n",
    "\n",
    "by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "/ [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates the basic workflow of using TensorFlow with a simple linear model. Instead of the ubiquitous MNIST, we will utilize the Google Doodles dataset and define and optimize a simple mathematical model in TensorFlow. The results are then plotted and discussed.\n",
    "\n",
    "Start here: https://quickdraw.withgoogle.com/data\n",
    "\n",
    "See also: https://www.tensorflow.org/versions/r1.0/get_started/mnist/pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathansherman/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was developed using Python 3.6.1 (Anaconda) and TensorFlow version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#data = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of MNIST data, we will load our doodle sets, which are in a different file format and must go through some formatting before we can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name-of-dataset']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "xtrn = h5py.File('data/doodle_data/x_train.h5', 'r')\n",
    "list(xtrn)\n",
    "ytrn = h5py.File('data/doodle_data/y_train.h5', 'r')\n",
    "list(ytrn)\n",
    "xtst = h5py.File('data/doodle_data/x_test.h5', 'r')\n",
    "list(xtst)\n",
    "ytst = h5py.File('data/doodle_data/y_test.h5', 'r')\n",
    "list(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"name-of-dataset\": shape (16000,), type \"<i8\">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrn.get('name-of-dataset')\n",
    "ytrn.get('name-of-dataset')\n",
    "xtst.get('name-of-dataset')\n",
    "ytst.get('name-of-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrn_data = list(xtrn['name-of-dataset'])\n",
    "ytrn_data = list(ytrn['name-of-dataset'])\n",
    "xtst_data = list(xtst['name-of-dataset'])\n",
    "ytst_data = list(ytst['name-of-dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrn_data = np.array(xtrn_data)\n",
    "ytrn_data = np.array(ytrn_data)\n",
    "xtst_data = np.array(xtst_data)\n",
    "ytst_data = np.array(ytst_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data consists of 80000 images with classification labels (numerical). They are split into 2 sets, training and testing.\n",
    "\n",
    "This means we are following the more basic approach (2 set) as described here: https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t64000\n",
      "- Test-set:\t\t16000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(ytrn_data)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(ytst_data)))\n",
    "#print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.27450982, 0.3647059 ,\n",
       "       0.33333334, 0.29411766, 0.05882353, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01960784, 0.9882353 , 1.        , 1.        , 1.        ,\n",
       "       0.972549  , 0.6666667 , 0.11764706, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09019608, 1.        ,\n",
       "       0.46666667, 0.13333334, 0.22352941, 0.5254902 , 0.9372549 ,\n",
       "       0.9490196 , 0.42352942, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.15686275, 1.        , 0.31764707, 0.        ,\n",
       "       0.        , 0.        , 0.09803922, 0.6784314 , 1.        ,\n",
       "       0.7294118 , 0.03137255, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.22745098,\n",
       "       1.        , 0.24705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.36078432, 0.9882353 , 0.6745098 ,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 1.        , 0.15294118,\n",
       "       0.34509805, 0.63529414, 0.1254902 , 0.        , 0.        ,\n",
       "       0.        , 0.40392157, 1.        , 0.43529412, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.60784316, 0.9254902 , 0.00392157, 0.6313726 , 1.        ,\n",
       "       0.9647059 , 0.49803922, 0.03529412, 0.        , 0.        ,\n",
       "       0.7137255 , 0.89411765, 0.02745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11372549, 0.96862745, 0.5803922 ,\n",
       "       0.        , 0.6745098 , 0.84705883, 0.61960787, 0.99215686,\n",
       "       0.8745098 , 0.1764706 , 0.        , 0.23137255, 1.        ,\n",
       "       0.40392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6117647 , 0.9607843 , 0.09803922, 0.        , 0.7137255 ,\n",
       "       0.75686276, 0.        , 0.21568628, 0.70980394, 0.24313726,\n",
       "       0.        , 0.        , 0.8       , 0.7254902 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.25882354, 0.9843137 , 0.5254902 ,\n",
       "       0.        , 0.        , 0.7529412 , 0.7176471 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6313726 , 0.8509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "       0.96862745, 0.79607844, 0.05098039, 0.        , 0.        ,\n",
       "       0.79607844, 0.6745098 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.5058824 , 0.972549  ,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01176471, 0.9098039 , 0.78039217, 0.05490196,\n",
       "       0.        , 0.        , 0.        , 0.8352941 , 0.63529414,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.7137255 , 0.9254902 , 0.01176471, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
       "       1.        , 0.43529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8901961 , 0.59607846, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3137255 , 1.        ,\n",
       "       0.40784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.99215686, 0.47843137,\n",
       "       0.        , 0.        , 0.        , 0.21960784, 1.        ,\n",
       "       0.3764706 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23529412, 0.92941177, 0.79607844, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.9490196 , 0.52156866, 0.        , 0.        ,\n",
       "       0.        , 0.6392157 , 0.93333334, 0.03921569, 0.        ,\n",
       "       0.        , 0.        , 0.3254902 , 0.96862745, 0.8235294 ,\n",
       "       0.10588235, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.9098039 ,\n",
       "       0.5647059 , 0.        , 0.        , 0.03137255, 0.972549  ,\n",
       "       0.9764706 , 0.84313726, 0.72156864, 0.15294118, 0.43137255,\n",
       "       0.99215686, 0.74509805, 0.05882353, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.74509805, 0.46666667, 0.        ,\n",
       "       0.        , 0.        , 0.3764706 , 0.54509807, 0.63529414,\n",
       "       0.8980392 , 0.92941177, 1.        , 0.6431373 , 0.02352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6117647 , 0.96862745,\n",
       "       0.78039217, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.8       , 0.8980392 , 0.9137255 , 0.05098039,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 1.        ,\n",
       "       0.50980395, 0.9764706 , 0.63529414, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.05490196,\n",
       "       0.        , 0.6784314 , 0.9019608 , 0.02745098, 0.45882353,\n",
       "       1.        , 0.36078432, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.7411765 , 0.87058824, 0.17254902, 0.5568628 ,\n",
       "       0.36078432, 0.        , 0.00784314, 0.7294118 , 0.94509804,\n",
       "       0.12156863, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17254902,\n",
       "       0.8745098 , 0.9490196 , 0.34901962, 0.00392157, 0.        ,\n",
       "       0.        , 0.11372549, 1.        , 0.42745098, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08235294, 0.75686276,\n",
       "       1.        , 0.8156863 , 0.31764707, 0.05098039, 0.14117648,\n",
       "       0.9843137 , 0.5294118 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00784314, 0.32941177, 0.8235294 ,\n",
       "       1.        , 1.        , 1.        , 0.92156863, 0.24705882,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00784314, 0.2901961 , 0.42352942,\n",
       "       0.4392157 , 0.08235294, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtst_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our data has integers assigned for its label, but is not in the one-hot vector form. We will need to convert the vector into a matrix of one-hot vectors. Turns out you can do it in one line of code - not bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrn_onehot = np.eye(np.max(ytrn_data)+1)[ytrn_data]\n",
    "\n",
    "ytst_onehot = np.eye(np.max(ytst_data)+1)[ytst_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data-set has been now been converted to one-hot encoding. This means the labels have been converted from a single number to a vector whose length equals the number of possible classes. All elements of the vector are zero except for the $i$'th element which is one and means the class is $i$. For example, the One-Hot encoded labels for the first 5 images in the test-set are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytst_onehot[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the classes as single numbers for various comparisons and performance measures, so we convert the One-Hot encoded vectors to a single number by taking the index of the highest element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the class for the first five images in the test-set. Compare these to the One-Hot encoded vectors above. For example, the class for the first image is at index 4, which corresponds to a One-Hot encoded vector where all elements are zero except for the element at index 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, 1, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytst_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dimensions are used in several places in the source-code below. In computer programming it is generally best to use variables and constants rather than having to hard-code specific numbers every time that number is used. This means the numbers only have to be changed in one single place. Ideally these would be inferred from the data that has been read, but here we just write the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length (e.g. 28 x 28 = 784).\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function for plotting images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a few images to see if data is correct\n",
    "\n",
    "Check not just the first 9 to see how data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 784) (16000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtst_data.shape, ytst_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD5CAYAAAC9FVegAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1JwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: 0  full%2Fnumpy_bitmap%2Fbeard.npy\n",
      "file: 1  full%2Fnumpy_bitmap%2Fbinoculars.npy\n",
      "file: 2  full%2Fnumpy_bitmap%2Fbrain.npy\n",
      "file: 3  full%2Fnumpy_bitmap%2Fclarinet.npy\n",
      "file: 4  full%2Fnumpy_bitmap%2Fear.npy\n",
      "file: 5  full%2Fnumpy_bitmap%2Feye.npy\n",
      "file: 6  full%2Fnumpy_bitmap%2Fgoatee.npy\n",
      "file: 7  full%2Fnumpy_bitmap%2Fhelmet.npy\n",
      "file: 8  full%2Fnumpy_bitmap%2Fkeyboard.npy\n",
      "file: 9  full%2Fnumpy_bitmap%2Flollipop.npy\n"
     ]
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = xtst_data[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = ytst_data[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images, cls_true)\n",
    "for indx, file in enumerate(os.listdir('data/doodle_src/')):\n",
    "    print(\"file: {0} \".format(indx), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph\n",
    "\n",
    "The entire purpose of TensorFlow is to have a so-called computational graph that can be executed much more efficiently than if the same calculations were to be performed directly in Python. TensorFlow can be more efficient than NumPy because TensorFlow knows the entire computation graph that must be executed, while NumPy only knows the computation of a single mathematical operation at a time.\n",
    "\n",
    "TensorFlow can also automatically calculate the gradients that are needed to optimize the variables of the graph so as to make the model perform better. This is because the graph is a combination of simple mathematical expressions so the gradient of the entire graph can be calculated using the chain-rule for derivatives.\n",
    "\n",
    "A TensorFlow graph consists of the following parts which will be detailed below:\n",
    "\n",
    "* Placeholder variables used to change the input to the graph.\n",
    "* Model variables (called tensors) that are going to be optimized so as to make the model perform better. These are connected as inputs and outputs of \"nodes\"\n",
    "* The nodes of the model which are essentially mathematical functions that calculates some output given the input in the placeholder variables and the model/tensor variables.\n",
    "* A cost measure that can be used to guide the optimization of the variables.\n",
    "* An optimization method which updates the variables of the model.\n",
    "\n",
    "In addition, the TensorFlow graph may also contain various debugging statements e.g. for logging data to be displayed using TensorBoard, which is not covered in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder variables serve as the input to the graph that we may change each time we execute the graph. We call this feeding the placeholder variables and it is demonstrated further below.\n",
    "\n",
    "First we define the placeholder variable for the input images. This allows us to change the images that are input to the TensorFlow graph. This is a so-called tensor, which just means that it is a multi-dimensional vector or matrix. The data-type is set to `float32` and the shape is set to `[None, img_size_flat]`, where `None` means that the tensor may hold an arbitrary number of images with each image being a vector of length `img_size_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_size_flat])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have the placeholder variable for the true labels associated with the images that were input in the placeholder variable `x`. The shape of this placeholder variable is `[None, num_classes]` which means it may hold an arbitrary number of labels and each label is a vector of length `num_classes` which is 10 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.placeholder(tf.float32, [None, num_classes])\n",
    "print(y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have the placeholder variable for the true class of each image in the placeholder variable `x`. These are integers and the dimensionality of this placeholder variable is set to `[None]` which means the placeholder variable is a one-dimensional vector of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "print(y_true_cls.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the placeholder variables that were defined above and which serve as feeding input data into the model, there are also some model variables that must be changed by TensorFlow so as to make the model perform better on the training data.\n",
    "\n",
    "The first variable that must be optimized is called `weights` and is defined here as a TensorFlow variable that must be initialized with zeros and whose shape is `[img_size_flat, num_classes]`, so it is a 2-dimensional tensor (or matrix) with `img_size_flat` rows and `num_classes` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(X, n_input, n_output, activation=None, scope=None):\n",
    "    with tf.variable_scope(scope or \"linear\"):\n",
    "        weights = tf.Variable(tf.zeros([n_input, n_output]))\n",
    "            #initializer=tf.random_normal_initializer(mean=0.0, stddev=0.1))\n",
    "        tf.summary.histogram(\"weights\", weights)\n",
    "        biases = tf.Variable(tf.zeros([n_output]))\n",
    "            #initializer=tf.constant_initializer())\n",
    "        tf.summary.histogram(\"biases\", biases)\n",
    "        if activation is None:\n",
    "            h = tf.matmul(X, weights) + biases\n",
    "        if activation is \"tanh\":\n",
    "            h = tf.nn.tanh(tf.matmul(X, weights) + biases, name='tanh')\n",
    "        if activation is \"sigmoid\":\n",
    "            h = tf.nn.sigmoid(tf.matmul(X, weights) + biases, name='sigmoid')\n",
    "        if activation is \"relu\":\n",
    "            h = tf.nn.relu(tf.matmul(X, weights) + biases, name='relu')\n",
    "        print(tf.shape(h))\n",
    "        return weights, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weights = tf.Variable(tf.zeros([img_size_flat, num_classes]))\n",
    "#tf.summary.histogram(\"weights\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second variable that must be optimized is called `biases` and is defined as a 1-dimensional tensor (or vector) of length `num_classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#biases = tf.Variable(tf.zeros([num_classes]))\n",
    "#tf.summary.histogram(\"biases\", biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple mathematical model multiplies the images in the placeholder variable `x` with the `weights` and then adds the `biases`.\n",
    "\n",
    "The result is a matrix of shape `[num_images, num_classes]` because `x` has shape `[num_images, img_size_flat]` and `weights` has shape `[img_size_flat, num_classes]`, so the multiplication of those two matrices is a matrix with shape `[num_images, num_classes]` and then the `biases` vector is added to each row of that matrix.\n",
    "\n",
    "Note that the name `logits` is typical TensorFlow terminology, but other people may call the variable something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"layer_1/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"layer_2/Shape:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"layer_3/Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#logits = tf.matmul(x, weights) + biases\n",
    "_, logits_a = linear(x, 784, 256, activation=None, scope='layer_1')\n",
    "_, logits_b = linear(logits_a, 256, 784, activation=None, scope='layer_2')\n",
    "weights, logits = linear(logits_b, 784, 10, activation=None, scope='layer_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder\n",
      "Placeholder_1\n",
      "Placeholder_2\n",
      "layer_1/zeros/shape_as_tensor\n",
      "layer_1/zeros/Const\n",
      "layer_1/zeros\n",
      "layer_1/Variable\n",
      "layer_1/Variable/Assign\n",
      "layer_1/Variable/read\n",
      "layer_1/weights/tag\n",
      "layer_1/weights\n",
      "layer_1/zeros_1\n",
      "layer_1/Variable_1\n",
      "layer_1/Variable_1/Assign\n",
      "layer_1/Variable_1/read\n",
      "layer_1/biases/tag\n",
      "layer_1/biases\n",
      "layer_1/MatMul\n",
      "layer_1/add\n",
      "layer_1/Shape\n",
      "layer_2/zeros/shape_as_tensor\n",
      "layer_2/zeros/Const\n",
      "layer_2/zeros\n",
      "layer_2/Variable\n",
      "layer_2/Variable/Assign\n",
      "layer_2/Variable/read\n",
      "layer_2/weights/tag\n",
      "layer_2/weights\n",
      "layer_2/zeros_1\n",
      "layer_2/Variable_1\n",
      "layer_2/Variable_1/Assign\n",
      "layer_2/Variable_1/read\n",
      "layer_2/biases/tag\n",
      "layer_2/biases\n",
      "layer_2/MatMul\n",
      "layer_2/add\n",
      "layer_2/Shape\n",
      "layer_3/zeros/shape_as_tensor\n",
      "layer_3/zeros/Const\n",
      "layer_3/zeros\n",
      "layer_3/Variable\n",
      "layer_3/Variable/Assign\n",
      "layer_3/Variable/read\n",
      "layer_3/weights/tag\n",
      "layer_3/weights\n",
      "layer_3/zeros_1\n",
      "layer_3/Variable_1\n",
      "layer_3/Variable_1/Assign\n",
      "layer_3/Variable_1/read\n",
      "layer_3/biases/tag\n",
      "layer_3/biases\n",
      "layer_3/MatMul\n",
      "layer_3/add\n",
      "layer_3/Shape\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations(): \n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `logits` is a matrix with `num_images` rows and `num_classes` columns, where the element of the $i$'th row and $j$'th column is an estimate of how likely the $i$'th input image is to be of the $j$'th class.\n",
    "\n",
    "However, these estimates are a bit rough and difficult to interpret because the numbers may be very small or large, so we want to normalize them so that each row of the `logits` matrix sums to one, and each element is limited between zero and one. This is calculated using the so-called softmax function and the result is stored in `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted class can be calculated from the `y_pred` matrix by taking the index of the largest element in each row.\n",
    "\n",
    "In simpler terms, we are squashing all the numbers down in our vector to less than 1 (normalization), and then choosing the largest value from the number of classes to be the predicted class. \n",
    "\n",
    "For example, if after the softmax function we have a vector of [0.1, 0.07, 0.03, 0.75, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0], then our \"argmax\" function would select 0.75 as the maximum value. This is the 4th element of our 10 classes, and thus we are predicting the input is a 3 (0 is the 1st element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-function to be optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the model better at classifying the input images, we must somehow change the variables for `weights` and `biases`. To do this we first need to know how well the model currently performs by comparing the predicted output of the model `y_pred` to the desired output `y_true`.\n",
    "\n",
    "The cross-entropy is a performance measure used in classification. The cross-entropy is a continuous function that is always positive and if the predicted output of the model exactly matches the desired output then the cross-entropy equals zero. The goal of optimization is therefore to minimize the cross-entropy so it gets as close to zero as possible by changing the `weights` and `biases` of the model.\n",
    "\n",
    "TensorFlow has a built-in function for calculating the cross-entropy. Note that it uses the values of the `logits` because it also calculates the softmax internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now calculated the cross-entropy for each of the image classifications so we have a measure of how well the model performs on each image individually. But in order to use the cross-entropy to guide the optimization of the model's variables we need a single scalar value, so we simply take the average of the cross-entropy for all the image classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cost:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)\n",
    "tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the basic form of Gradient Descent where the step-size is set to 0.5.\n",
    "\n",
    "Note that optimization is not performed at this point. In fact, nothing is calculated at all, we just add the optimizer-object to the TensorFlow graph for later execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a few more performance measures to display the progress to the user.\n",
    "\n",
    "This is a vector of booleans whether the predicted class equals the true class of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calculates the classification accuracy by first type-casting the vector of booleans to floats, so that False becomes 0 and True becomes 1, and then calculating the average of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.498272711733015&quot;).pbtxt = 'node {\\n  name: &quot;Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Placeholder_2&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;layer_1/zeros/shape_as_tensor&quot;\\n  input: &quot;layer_1/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_1/Variable&quot;\\n  input: &quot;layer_1/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_1/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_1/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_1/weights/tag&quot;\\n  input: &quot;layer_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 256\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_1/Variable_1&quot;\\n  input: &quot;layer_1/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_1/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/biases/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_1/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/biases&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_1/biases/tag&quot;\\n  input: &quot;layer_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;layer_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_1/MatMul&quot;\\n  input: &quot;layer_1/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_1/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\001\\\\000\\\\000\\\\020\\\\003\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;layer_2/zeros/shape_as_tensor&quot;\\n  input: &quot;layer_2/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 256\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_2/Variable&quot;\\n  input: &quot;layer_2/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_2/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_2/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_2/weights/tag&quot;\\n  input: &quot;layer_2/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 784\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_2/Variable_1&quot;\\n  input: &quot;layer_2/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_2/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/biases/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_2/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/biases&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_2/biases/tag&quot;\\n  input: &quot;layer_2/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;layer_1/add&quot;\\n  input: &quot;layer_2/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_2/MatMul&quot;\\n  input: &quot;layer_2/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_2/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/zeros/shape_as_tensor&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/zeros/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/zeros&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;layer_3/zeros/shape_as_tensor&quot;\\n  input: &quot;layer_3/zeros/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_3/Variable&quot;\\n  input: &quot;layer_3/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_3/Variable&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/weights/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_3/weights&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/weights&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_3/weights/tag&quot;\\n  input: &quot;layer_3/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/zeros_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;layer_3/Variable_1&quot;\\n  input: &quot;layer_3/zeros_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Variable_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;layer_3/Variable_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/biases/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;layer_3/biases&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/biases&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;layer_3/biases/tag&quot;\\n  input: &quot;layer_3/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;layer_2/add&quot;\\n  input: &quot;layer_3/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;layer_3/MatMul&quot;\\n  input: &quot;layer_3/Variable_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;layer_3/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_3/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Softmax&quot;\\n  op: &quot;Softmax&quot;\\n  input: &quot;layer_3/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;Softmax&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_3/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_3/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Rank_1&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Shape_1&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice/begin&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat/values_0&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;layer_3/add&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Rank_2&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Shape_2&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_1/begin&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat_1/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat_1/values_0&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_1&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;Placeholder_1&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Rank&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Shape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_2/begin&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;softmax_cross_entropy_with_logits/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape_2&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;cost&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;cost&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;cost/tags&quot;\\n  input: &quot;Mean&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_2&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;softmax_cross_entropy_with_logits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;softmax_cross_entropy_with_logits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims&quot;\\n  input: &quot;softmax_cross_entropy_with_logits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax&quot;\\n  op: &quot;LogSoftmax&quot;\\n  input: &quot;softmax_cross_entropy_with_logits/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/LogSoftmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_2_grad/Reshape&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/ExpandDims_1&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/softmax_cross_entropy_with_logits_grad/mul&quot;\\n  input: &quot;^gradients/softmax_cross_entropy_with_logits_grad/mul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/mul&quot;\\n  input: &quot;^gradients/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/softmax_cross_entropy_with_logits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/mul_1&quot;\\n  input: &quot;^gradients/softmax_cross_entropy_with_logits_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/softmax_cross_entropy_with_logits_grad/mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_3/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_3/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/layer_3/add_grad/Shape&quot;\\n  input: &quot;gradients/layer_3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/layer_3/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_3/add_grad/Sum&quot;\\n  input: &quot;gradients/layer_3/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/softmax_cross_entropy_with_logits/Reshape_grad/Reshape&quot;\\n  input: &quot;gradients/layer_3/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_3/add_grad/Sum_1&quot;\\n  input: &quot;gradients/layer_3/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_3/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_3/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_3/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_3/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/layer_3/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_3/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/layer_3/add_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_3/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;layer_2/add&quot;\\n  input: &quot;gradients/layer_3/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/layer_3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_2/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 784\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/layer_2/add_grad/Shape&quot;\\n  input: &quot;gradients/layer_2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/layer_3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/layer_2/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_2/add_grad/Sum&quot;\\n  input: &quot;gradients/layer_2/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/layer_3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/layer_2/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_2/add_grad/Sum_1&quot;\\n  input: &quot;gradients/layer_2/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_2/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_2/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_2/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_2/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/layer_2/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_2/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/layer_2/add_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_2/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;layer_1/add&quot;\\n  input: &quot;gradients/layer_2/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/layer_2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;layer_1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 256\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/layer_1/add_grad/Shape&quot;\\n  input: &quot;gradients/layer_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/layer_1/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_1/add_grad/Sum&quot;\\n  input: &quot;gradients/layer_1/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/layer_2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/layer_1/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/layer_1/add_grad/Sum_1&quot;\\n  input: &quot;gradients/layer_1/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_1/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_1/add_grad/Reshape&quot;\\n  input: &quot;^gradients/layer_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_1/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_1/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/layer_1/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_1/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/layer_1/add_grad/tuple/control_dependency&quot;\\n  input: &quot;layer_1/Variable/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Placeholder&quot;\\n  input: &quot;gradients/layer_1/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/layer_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/layer_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/layer_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_1/Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_1/Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_1/Variable_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_1/Variable_1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_1/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_1/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_2/Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_2/Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_2/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_2/Variable_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_2/Variable_1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_2/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_2/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_3/Variable/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_3/Variable&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_3/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_layer_3/Variable_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;layer_3/Variable_1&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/layer_3/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@layer_3/Variable_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_layer_1/Variable/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_layer_1/Variable_1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_layer_2/Variable/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_layer_2/Variable_1/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_layer_3/Variable/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_layer_3/Variable_1/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;Equal&quot;\\n  op: &quot;Equal&quot;\\n  input: &quot;ArgMax&quot;\\n  input: &quot;Placeholder_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;Equal&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean_1&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Cast&quot;\\n  input: &quot;Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Merge/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;layer_1/weights&quot;\\n  input: &quot;layer_1/biases&quot;\\n  input: &quot;layer_2/weights&quot;\\n  input: &quot;layer_2/biases&quot;\\n  input: &quot;layer_3/weights&quot;\\n  input: &quot;layer_3/biases&quot;\\n  input: &quot;cost&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 7\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^layer_1/Variable/Assign&quot;\\n  input: &quot;^layer_1/Variable_1/Assign&quot;\\n  input: &quot;^layer_2/Variable/Assign&quot;\\n  input: &quot;^layer_2/Variable_1/Assign&quot;\\n  input: &quot;^layer_3/Variable/Assign&quot;\\n  input: &quot;^layer_3/Variable_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.498272711733015&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "    \n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorFlow session\n",
    "\n",
    "Once the TensorFlow graph has been created, we have to create a TensorFlow session which is used to execute the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "## merge all our Tensorboard summaries and create file directory\n",
    "summaryMerged = tf.summary.merge_all()\n",
    "filename=\"./summary_log_qd/run\"+datetime.datetime.now().strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "writer = tf.summary.FileWriter(filename, session.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n",
    "The variables for `weights` and `biases` must be initialized before we start optimizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to perform optimization iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There are 50.000 images in the training-set. It takes a long time to calculate the gradient of the model using all these images. We therefore use Stochastic Gradient Descent which only uses a small batch of images in each iteration of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for performing a number of optimization iterations so as to gradually improve the `weights` and `biases` of the model. In each iteration, a new batch of data is selected from the training-set and then TensorFlow executes the optimizer using those training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    x_batch = [] \n",
    "    y_true_batch = []\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.        \n",
    "        \n",
    "        #uncomment and insert if random batch sampling desired\n",
    "        #idxs = np.random.permutation(range(len(xs)))\n",
    "        \n",
    "        n_batches = len(ytrn_data) // batch_size\n",
    "        for batch_i in range(n_batches):\n",
    "            x_batch = xtrn_data[batch_i * batch_size: (batch_i + 1) * batch_size, :]\n",
    "            y_true_batch = ytrn_onehot[batch_i * batch_size: (batch_i + 1) * batch_size, :]\n",
    "            # Put the batch into a dict with the proper names\n",
    "            # for placeholder variables in the TensorFlow graph.\n",
    "            # Note that the placeholder for y_true_cls is not set\n",
    "            # because it is not used during training.\n",
    "            feed_dict_train = {x: x_batch,\n",
    "                               y_true: y_true_batch}\n",
    "\n",
    "            # Run the optimizer using this batch of training data.\n",
    "            # TensorFlow assigns the variables in feed_dict_train\n",
    "            # to the placeholder variables and then runs the optimizer.\n",
    "            _, sumOut = session.run([optimizer,summaryMerged], feed_dict=feed_dict_train)\n",
    "            #sumOut = session.run(summaryMerged, feed_dict=feed_dict_train)\n",
    "        \n",
    "            if i % 10 == 0:\n",
    "                writer.add_summary(sumOut, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-functions to show performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dict with the test-set data to be used as input to the TensorFlow graph. Note that we must use the correct names for the placeholder variables in the TensorFlow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict_test = {x: xtst_data,\n",
    "                  y_true: ytst_onehot,\n",
    "                  y_true_cls: ytst_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for printing the classification accuracy on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for printing and plotting the confusion matrix using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = ytst_data\n",
    "    \n",
    "    # Get the predicted classifications for the test-set.\n",
    "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting examples of images from the test-set that have been mis-classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    feed_dict=feed_dict_test)\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = xtst_data[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = ytst_data[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper-function to plot the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting the `weights` of the model. 10 images are plotted, one for each digit that the model is trained to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_weights():\n",
    "    # Get the values for the weights from the TensorFlow variable.\n",
    "    w = session.run(weights)\n",
    "    \n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Create figure with 3x4 sub-plots,\n",
    "    # where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(3, 4)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only use the weights for the first 10 sub-plots.\n",
    "        if i<10:\n",
    "            # Get the weights for the i'th digit and reshape it.\n",
    "            # Note that w.shape == (img_size_flat, 10)\n",
    "            image = w[:, i].reshape(img_shape)\n",
    "\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance before any optimization\n",
    "\n",
    "The accuracy on the test-set is 9.8%. This is because the model has only been initialized and not optimized at all, so it always predicts that the image shows a zero digit, as demonstrated in the plot below, and it turns out that 9.8% of the images in the test-set happens to be zero digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 10.2%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after 1 optimization iteration\n",
    "\n",
    "Already after a single optimization iteration, the model has increased its accuracy on the test-set to 64.4% up from 10.2%. This means that it mis-classifies the images about 4out of 10 times, as demonstrated on a few examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 9.7%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAD5CAYAAACj3GcTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFPik6TiOkwKfNB3HcVLw/xPhGSO1KohsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights can also be plotted as shown below. Positive weights are red and negative weights are blue. These weights can be intuitively understood as image-filters.\n",
    "\n",
    "For example, the weights used to determine if an image shows a zero-digit have a positive reaction (red) to an image of a circle, and  have a negative reaction (blue) to images with content in the centre of the circle.\n",
    "\n",
    "Similarly, the weights used to determine if an image shows a one-digit react positively (red) to a vertical line in the centre of the image, and react negatively (blue) to images with content surrounding that line.\n",
    "\n",
    "Note that the weights mostly look like the digits they're supposed to recognize. This is because only one optimization iteration has been performed so the weights are only trained on 100 images. After training on several thousand images, the weights become more difficult to interpret because they have to recognize many variations of how digits can be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD5CAYAAAAZf+9zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJakRC1iSGrGAJamR/weiDMFhSvCzJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after 10 optimization iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fbd9e11c7aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We have already performed 1 iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-e382fc94bde2>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# TensorFlow assigns the variables in feed_dict_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# to the placeholder variables and then runs the optimizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msumOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaryMerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;31m#sumOut = session.run(summaryMerged, feed_dict=feed_dict_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathansherman/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We have already performed 1 iteration.\n",
    "optimize(num_iterations=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after 100 optimization iterations\n",
    "\n",
    "After 100 optimization iterations, the model only mis-classifies about one in ten images. As demonstrated below, some of the mis-classifications are justified because the images are very hard to determine with certainty even for humans, while others are quite obvious and should have been classified correctly by a good model. But this simple model cannot reach much better performance and more complex models are therefore needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have already performed 10 iterations.\n",
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_example_errors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has now been trained for 100 optimization iterations, with each iteration using 100 images from the training-set. Because of the great variety of the images, the weights have now become difficult to interpret and we may doubt whether the model truly understands how digits are composed from lines, or whether the model has just memorized many different variations of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print and plot the so-called confusion matrix which lets us see more details about the mis-classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now done using TensorFlow, so we close the session to release its resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This has been commented out in case you want to modify and experiment\n",
    "# with the Notebook without having to restart it.\n",
    "#session.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "These are a few suggestions for exercises that may help improve your skills with TensorFlow. It is important to get hands-on experience with TensorFlow in order to learn how to use it properly.\n",
    "\n",
    "You may want to backup this Notebook before making any changes.\n",
    "\n",
    "* Change the learning-rate for the optimizer.\n",
    "* Change the optimizer to e.g. `AdagradOptimizer` or `AdamOptimizer`.\n",
    "* Change the batch-size to e.g. 1 or 1000.\n",
    "* How do these changes affect the performance?\n",
    "* Do you think these changes will have the same effect (if any) on other classification problems and mathematical models?\n",
    "* Do you get the exact same results if you run the Notebook multiple times without changing any parameters? Why or why not?\n",
    "* Change the function `plot_example_errors()` so it also prints the `logits` and `y_pred` values for the mis-classified examples.\n",
    "* Use `sparse_softmax_cross_entropy_with_logits` instead of `softmax_cross_entropy_with_logits`. This may require several changes to multiple places in the source-code. Discuss the advantages and disadvantages of using the two methods.\n",
    "* Remake the program yourself without looking too much at this source-code.\n",
    "* Explain to a friend how the program works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License (MIT)\n",
    "\n",
    "Copyright (c) 2016 by [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
